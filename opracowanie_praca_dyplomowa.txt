Jak opisać co to jest lower approximation and upper approximation:

The lower approximation of the set consists
of all the samples that can be described as definitely
belonging to the set, “positive cases”, whilst the upper
approximation of the set consists of all the samples that are
described as possibly belonging to the set, “possible cases”

Ogólnie wszedzie gdzie sie to czyta to Rough Set sa uzywane

do resukcji cech. I u nas tez to robimy, bo mowimy, ze dzielimy
obszar na mniejsze podobszary i pozniej tworzymy regule na tej 
podstawie.

Najwazniejsze co trzeba opisac to Information System:
czyli wiedza, ktora jest zawarta w materiale uczacym 
(knowledge about the domain). An information system can 
be designed as a decision table. 

Opisać co to jest Indiscernibility Relation.

Bardzo wazne jest aby opisac temat zwiazany z Data discretization.
Tutaj ciekawym aspektem jest clusetization, to pomaga analizowac 
strukture przestrzeni danego atrybutu. In terms of its high
dimensionality, discovering clusters of arbitrary shapes, and
dealing with different types of attributes, a hierarchical
clustering method is presented [3] and adopted for data
discretization before attribute reduction. This method has
advantages such as embedded flexibility regarding the level
of granularity and ease of handling any forms of similarity
or distances. It can be divided into agglomerative and
divisive algorithms.

Potem musimy opisać czym jest Feature Reduction:

, zmniejsza to
zlozonosc problemu. The aim of attribute reduction is to find a minimal
subset of related attributes that preserves the classification
accuracy of the original attributes of the decision table. Consistency
principle- opisac co to w ogole jest.
Rough sets seeks data reduction
through the concept of equivalence classes



Opisać co to jest fuzzy logic:

A fuzzy set can be represented as membership
function μ that associates with each element x of the
universe of disclosure X, a number μ(x), i.e. membership
grade, in the interval [0, 1]. Dwa typy funckji klasyfikujacych:
= jednolite albo 1 albo zero
= jednostajne tzn. od 1 do zera.

Opisać co to jest entropy-based method i na czym ona 
polega

Główna zaleta RoughSet:

An important idea of rough sets is to remove redundant
attributes where there is a large amount of sample data.
Elimination of redundant attributes can help identify strong,
non-redundant classification rules. The rough set method
for feature selection is particularly useful for dealing with
imprecise, inconsistent and overlapping information.

N-fold cross-validation- czy bedzie to potrzebne, czy trzeba
tego uzywac i jak ogolnie to trzeba zrobic.

The most important fact about Rough Sets is that feature 
reduction is NP-hard problem.
The computation of all minimal
length decision rules in order to manage the uncertainty in ex-
pert systems was proposed by Grzymala-Busse [2]. A variable
precision model of rough sets was generalized and introduced
by Ziarko [3]. The incremental identification of decision rules
was proposed by Skowron et al. [4], whose study also elabo-
rated the discernibility matrices and functions. Shan et al. [5]
proposed an incremental algorithm for identifying all minimal
length decision rules. WZIETE Z ARTYKULU art_40.pdf

Model decision table include condition attributes, condition attribute
values and decision classes.

firstly we have to find lower approximation which gives certain decision
about class of a given object x. This is the first step before going into 
deriving decision rules of minimal length.

Generally when we talk about rough set we have information system 
and a decision system. The former includes a finite set of objects and
attributes. A decision system deals with condition attribute values.

W art_40 jest bardzo dokladnie opisane co to jest information system, 
co to jest decision system, a takze jest podany przyklad.

However,
there are some differences in describing the uncertainty and
incomplete knowledge. Fuzzy sets emphasize the vagueness
of a set, but rough set theory base on the indiscernibility of
objects in universe. The method of rough sets is the
expression and reduction of the knowledge and fuzzy sets is


W artykule art_36.pdf jest opisane jaka jest relacja pomiedzy 
Rough Set i Fuzzy Logic.

Feature reduction and Zipf's law.

Czy jest ogólnie istota rozpoznawania:
A role of classification is to classify objects, events and
real-life situations into classes. Each of the reviewed
objects is unique, original and its classification means a
certain degree of generalization. Let’s define a system
for the particular objects i.e. input and output variables,
elements (objects) and their mutual relations. Defining
and collecting the data of input/output variables cannot
be generalized, even though this stage influences the
classification result. An application of classification
methods based on computational intelligence (CI)
represents an effective tool for realization of a
classification model.

Every investigated object is connected to a specific piece
of information, to specific data. The objects which are
characterized by the same pieces of information are
mutually undistinguishable from the point of view of the
accessible pieces of information. This is expressed in
RST by the indiscernibity relations.


Values of attribute
may be uncertain because of many reasons. Generally
we can define four types of uncertainty: discretization of
quantitative attributes; imprecise values of quantitative
attribute; multiple values of attribute and unknown or
missing values of attribute.

The assumption that objects can be seen only through
the information available about them leads to the view
that knowledge has granular structure. Thus some
objects appear as similar and undiscerned. Therefore in
RST we assume that any vague concept is replaced by a
pair of precise concepts – the lower and the upper
approximation of the vague concept.

The effort to maximize accuracy leads to the
disproportionate rise of the number of definitions and
conditions.
The solution to deal with continuous valued attributes is to
partition numeric variables into a number of intervals and
treat each such interval as a category. This process of
partitioning continuous variables is usually termed as
discretization. Data can be reduced and simplified through
discretization. In case of continuous valued attributes, large
number of objects are generated with a very few objects
mapping into each of these classes. 

W moich opracowaniach mozna wprowadzic KHAT statistic.
This statistics
serves as an indicator of the extent to which the percentage
correct values of an error matrix are due to "true" agreement
versus chance agreement, for example a K value of 0.67 can
be thought of as an indication that an observed classification is
67% better than the one resulting from chance.
The KHAT statistics is computed as

Opisac na czym polega cross-validation:
Cross-Validation is a statistical method of evaluating
and comparing learning algorithms by dividing data
into two segments: one used to learn or train a model
and the other used to validate the model. In typical
cross-validation, the training and validation sets must
cross-over in successive rounds such that each data
point has a chance of being validated against. The basic
form of cross-validation is k-fold cross-validation.
Other forms of cross-validation are special cases of
k-fold cross-validation or involve repeated rounds
of k-fold cross-validation.

Napisac pare slow na temat indiscernibility ( new_6).
To find irreductible set of cuts P in the decision system 
is NP-complete while the effort to find the optimal set of cuts 
P in a decision system is NP-hard.

Opisać najważniejsze sposoby cięcia tych zbiorów (new_8...)

The theory of FSs, due to prof. Zadeh, is a
relatively new approach to uncertainty. In this
theory an element belongs to a set according to the
membership degree (membership function values)
[44,45,46], i.e. in a closed interval. It is an
enlargement of the traditional sets theory in which
an element either is or is not a set member. If we
endeavour to describe and model a particular reality
problem we encounter a certain discrepancy. On one
hand, there is the accuracy of mathematical methods
by which a specific problem is described and, on the
other hand, there is a very complicated reality
necessitating a range of simplifications and the
consequent inaccuracy, infidelity of the model
arising from them.

For our convenience in this paper four types of
uncertainty [41] need to be distinguished:
discretization of quantitative attributes; imprecise
values of quantitative attribute; multiple values of
attribute and unknown or missing values of attribute


The theory FSs and RST are now attracting attention
among researchers due to the representation of the
knowledge processing. These two theories
complement each other and as such they constitute
important components of CI. There are various
extensions of these two theories for processing.
The developments of rough and fuzzy extensions
to the data processing make the hybrid approaches
potentially rewarding research opportunities as well.
A rough-fuzzy approach [25] has two main lines of
thought in a hybridization of fuzzy and rough sets,
the constructive approach and the axiomatic
approach. The first one, generalized LA and UA are
defined based on fuzzy relations that are called
fuzzy-rough sets. The second [25] approach
introduces the definitions for generalized fuzzy LA
and fuzzy UA operators determined by a residual.
The assumptions are found that allow a given fuzzy
set-theoretic operator to represent LA or UA from a
fuzzy relation. Different types of fuzzy relations
produce different classes of fuzzy-rough set
algebras.

Intelligent pattern recognition systems have been success-
ful in many application areas. However, complex applica-
tion problems, such as reliable monitoring and diagnosis of
industrial plants and rapid detection and estimation of en-
vironmental changes, have emphasised the issue of knowl-
edge acquisition and modelling. These problems are likely
to present large numbers of features, not all of which will
be essential for the task at hand. Inaccurate and=or uncertain
values cannot be ruled out, either. Furthermore, such appli-
cations typically require convincing explanations about the
inference performed. A method to allow automated gener-
ation of knowledge models of clear semantics is, therefore,
highly desirable.
The most common approach to developing expressive and
human readable representations of knowledge is the use of
if-then production rules. Yet, real-life problem domains
usually lack generic and systematic expert rules for map-
ping feature patterns onto their underlying classes.
rough set theory [5], reduces
the dimensionality of potentially very large feature sets
without losing information needed for rule induction,
insofar as this is possible in the domain at hand. It
has an advantageous side-e ect in that it removes re-
dundancy from the historical data. This also helps sim-
plify the design and implementation of the actual pattern
classiÿer itself, by determining what features should be
made available to the system.

Napisac troche o importance region, ktory wyznaczany jest 
na tej samej podstawie co ja licze w swojej pracy na temat
Rough Set (wiecej informacji znajduje sie w artykule (new_10.pdf)

Na czym polega supervised i unsupervised learning?

The basic operators in rough set theory are approximations. There are at
least two approaches for the development of the rough set theory, the con-
structive and axiomatic approaches. In constructive approach, binary relations
on the universe, partitions of the universe, neighborhood systems, and Boolean
algebras are all the primitive notions. The lower and upper approximation
operators are constructed by means of these notions The constructive approach is suitable for practical applications of rough sets.
On the other hand, the axiomatic approach, which is appropriate for studying
the structures of rough set algebras, takes the lower and upper approximation
operators as primitive notions. In this approach, a set of axioms is used to
characterize approximation operators that are the same as the ones produced
by using constructive approach
On the other hand, by using an equivalence relation on
U , one can introduce lower and upper approximations in fuzzy set theory to
obtain an extended notion called rough fuzzy set [2,3]. Alternatively, a fuzzy
similarity relation can be used to replace an equivalence relation. The result is a
deviation of rough set theory called fuzzy rough sets

Najwazniejsze o co w tym wszystkim chodzi to idea crisp sets
In this paper we present a multi-scale method based on the hybrid notion of rough fuzzy sets, com-
ing from the combination of two models of uncertainty like vagueness by handling rough sets and
coarseness by handling fuzzy sets.
Rough sets embody the idea of indiscernibility between objects in a set, while
fuzzy sets model the ill-definition of the boundary of a sub-class of this
set. Marrying both
notions lead to consider, as instance, approximation of sets by means of
similarity rela-
tions or fuzzy partitions. The proposed multi-scale mechanism, based on the
model of
rough fuzzy sets, named C-calculus, introduced by Caianiello [9] is adopted to
spread
out local into more global information.
Fuzzy rough sets were proposed as a mathematical tool to deal with uncertainty. Noise is a main source of uncertainty
in real-world applications. We show that fuzzy rough sets are very sensitive to mislabeled samples. we introduce a
robust model of fuzzy rough sets in this work, called soft fuzzy rough sets and discuss the connections between the
soft fuzzy rough set model and other models. In addition, we design a soft fuzzy rough classifier based on the model.

Odnosnie Fuzzy-Sets:
An important idea is inspired by neuro biology re-
sults. They postulate that human learning e.g. speech
acquisition is also a process of reducing a rich parameter
set. Therefore, the structure of the fuzzy rule base sys-
tem is enlarged at the beginning and reduced during the
learning process.
The process of fuzzy logic is explained in Algorithm 1: Firstly, a crisp set
of input data are gathered and converted to a fuzzy set using fuzzy linguistic
variables, fuzzy linguistic terms and membership functions. This step is known
as fuzzification. Afterwards, an inference is made based on a set of rules. Lastly,
the resulting fuzzy output is mapped to a crisp output using the membership
functions, in the defuzzification step.
Define the linguistic variables and terms (initialization)
Construct the membership functions (initialization)
Construct the rule base (initialization)
Convert crisp input data to fuzzy values
using the membership functions (fuzzification)
5. Evaluate the rules in the rule base (inference)
6. Combine the results of each rule (inference)
7. Convert the output data to non-fuzzy values (defuzzification)

The use of fuzzy systems for automation tasks is
highly increasing within the past decade. Fuzzy
logic controller or fuzzy rule-based systems
(FRBS) provide a formal method for the repre-
sentation and approximation of imprecisely
known relationships by encoding them in the an-
tecedent and consequent parts of rules. The FRBS
models the human decision making process by
means of the collection of rules.

GAs have been proved to be a
new powerful optimization method able to over-
come the local minimum problem. In 1989, Karr et
al. [13] introduced the use of GAs for fuzzy sys-
tems optimization. Since then, some genetic-based
approaches for structural and parametrical tuning
have been proposed with the aim to design and
optimize fuzzy system e.g., [14±16] or to minimize
the number of MFs per variable by e.g., [17±19]. A
comparative study where genetic parameters eect
the learning of FRBS presented in [20]. Glorennec
[14] suggests a GA based method for fuzzy systems
structural and parametrical tuning. The method
produce fuzzy systems with minimal number of
rules, but it does not focus on the reduction of
membership functions per variable. Wong and
Ling [17] try to eliminate MF's whose middle value
exceeds the corresponding variable domain during
genetic process. A GA based on virus theory of
evolution is used in [21]. The rule structure is en-
coded in chromosomes, while validity bits are used
to cancel the less signi®cant parts of the rule base.
After the optimization, the MFs are labeled with
linguistic terms according to the order of the
middle points e.g., small, normal, big for three
MFs so that the linguistic rules are achieved. This
rules can be regarded, understand, reused and
maintained by users.

Fuzzy systems are based on Fuzzy Set Theory
[24]. A number of rules is used to model the way
that a system behaves. Fuzzy rules are constructed
in the well-known IF±THEN form. When crisp
values are given as input for an FRBS, they are
converted to degrees of membership in the various
linguistic values used by the system. This normal-
ization process of dierent universe of discourses
to 0; 1 allows to compare dierent input values
and to use linguistic concepts like ``small'', ``near''
or ``approximately''.

Knowledge representation in terms of understandable 
linguistic rules
diers signi®cantly from the black-box approach
used by other methods (e.g., neural networks).
Each set of crisp input values activates a num-
ber of rules to some degree. The degree to which
rules are activated is calculated by combining the
degrees of membership (subpremises) with the
fuzzy AND operator. This leads to the total acti-
vation of the rule. Supposing that the kth rule of
the system is


Traditional optimization methods are based on
the fact that certain functions are dierentiable.
Unfortunately, in many real world problems such
functions cannot be de®ned. But even if they can,
gradient search methods may not ®nd global op-
timal solutions. A possible way to overcome such
problems is to use GAs. Generally, a GA consists
of a problem, a number of encoded solutions for
that problem, some genetic operators which pro-
duce new solutions and a ®tness function which
says how good a particular solution for the prob-
lem is seen in Fig. 2.
Usually the ®tness function describes the ag-
gregation of some desired properties for the solu-
tions and is not necessarily dierentiable. Each
solution is encoded as a chromosome by binary or
real values. A population consists of a number of
individuals represented by chromosomes. A pop-
ulation at a certain time step is a generation. Ge-
netic operators are applied to each generation to
produce the next generation. Common genetic
operators are selection, crossover and mutation.
During selection, individuals with high ®tness
values within the current population are selected
to build the basis for the new generation. Cross-
over is a way of creating new solutions by ran-
domly selecting two chromosomes of previous
solutions from the gene pool and exchanging
portions of their strings. Mutation is performed
upon a selected chromosome by randomly
changing a part of its coded value. Mutation is
needed to ensure diversity in the population.

Up to now a lot of work has been done in
combining fuzzy systems and genetic algorithms
[6]. Fuzzy±genetic combinations can be classi®ed
in two categories. On one hand fuzzy techniques
are used to improve GA behavior [18] and to
model GA components [31]. On the other GAs are
used to optimize the structure of the fuzzy system
and the I/O behavior
In the above-mentioned studies, fuzzy-rule-based systems were mainly applied to control problems. Since
control problems and classification problems are different from each other, we cannot apply fuzzy control
methods to fuzzy-rule-based classification systems. For example, in fuzzy control the inference step consists
of composing the outputs of all rules then applying a defuzzification procedure while in fuzzy-rule-based
classification the outcome of each rule is independent and a method is provided for determining which rule
outcome to accept.

Fuzzy rule-based systems have been successfully applied to various application areas such as control
and classification [20,21]. While the main objective in the design of fuzzy rule-based systems has been
the performance maximization, their comprehensibility has also been taken into account in some recent
studies [3,4,19,24,25,27,28]. The comprehensibility of fuzzy rule-based systems is related to various
factors:
(i) Comprehensibility of fuzzy partitions (e.g., linguistic interpretability of each fuzzy set, separation
of neighboring fuzzy sets, the number of fuzzy sets for each variable).
(ii) Simplicity of fuzzy rule-based systems (e.g., the number of input variables, the number of fuzzy
if-then rules).
(iii) Simplicity of fuzzy if-then rules (e.g., type of fuzzy if-then rules, the number of antecedent
conditions in each fuzzy if-then rule).
(iv) Simplicity of fuzzy reasoning (e.g., selection of a single winner rule, voting by multiple rules).
.1 Fuzzy If-Then Rules for Pattern Classification Problems
In our approach, first fuzzy if-then rules are generated from numerical data. Then the generated rules
are used as candidate rules from which a small number of fuzzy if-then rules are selected by multi-
objective genetic algorithms. Let us assume that we have m labeled patterns x p = ( x p 1 , ..., x pn ) ,
p = 1, 2..., m from M classes in an n-dimensional continuous pattern space. We also assume that the
domain interval of each attribute x i is discretized into K i linguistic values (i.e., K i fuzzy sets with
linguistic labels). Some typical examples of fuzzy discretization are shown in Fig. 1.
For a given x ൌ ሺxଵ , xଶ , ... , x୬ ሻ in an n-dimensional pattern space, the ith fuzzy rule (R୧ ሻ
type can be:
Ishibuchi rule type with a class label (C୧ ) in the consequent part [3]:
ܴ‫ܴ	݈݁ݑ‬௜ : ‫ݔ	݂ܫ‬ଵ 	݅‫ܣ	ݏ‬௜ଵ 	ܽ݊݀	 ... ܽ݊݀	‫ݔ‬௡ 	݅‫ܣ	ݏ‬௜௡ 	‫ܥ	ݏݏ݈ܽܥ	݄݊݁ݐ‬௜ 	
where A୧ଵ , ... , A୧୬ are antecedent fuzzy sets associated to linguistic terms. There is also
another extension of this rule type which assigns each rule a weight (W୧ ) or a soundness
degree [2] which shows the degree of certainty of the rule:
ܴ‫ܴ	݈݁ݑ‬௜ ∶ ‫ݔ	݂ܫ‬ଵ 	݅‫ܣ	ݏ‬௜ଵ	ܽ݊݀	 ... ܽ݊݀	‫ݔ‬௡ 	݅‫ܣ	ݏ‬௜௡ 	‫ܹ	݄ݐ݅ݓ	݅ܥ	ݏݏ݈ܽܥ		݄݊݁ݐ‬௜ 	
The Ishibuchi rule type is more applicable for pattern classification problems and has
higher interpretability than the other types of rules such as Mamdani and TKS[2] and is
the focus of this paper. We have extended the Ishibuchi classification rule type for rule-
based pattern classification. The proposed rule structure in this paper for uncertain rule-
based pattern classification, for a given pattern X ൌ(xଵ , ... , x୬ ሻ	is as follow


